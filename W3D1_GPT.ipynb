{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1sS8SHkmPa4r"
      },
      "source": [
        "# GPT from scratch (but very very small)\n",
        "In this notebook we will build a GPT-style transformer from scratch. Heavily based on [nanoGPT](https://github.com/karpathy/nanoGPT) and [minGPT](https://github.com/karpathy/minGPT/tree/master) by Andrej Karpathy.\n",
        "\n",
        "Emphasis on readable code, minimal and simple implementations, and (relatively) fast training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yDGkYgl4-nq9"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import pickle\n",
        "from matplotlib import pyplot as plt\n",
        "from tqdm.auto import tqdm, trange\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "from torch.utils.data import RandomSampler, random_split\n",
        "\n",
        "DEVICE = torch.device('cuda') # 'mps' for ARM macbooks, 'cuda' for GPU, 'cpu' otherwise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfyJ5-PCPa4t"
      },
      "source": [
        "## Data\n",
        "We use the tiny shakespeare dataset to train a character level transformer to predict text that looks like shakespeare. All data is in one text file, which we download below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r7eqwjNC-wbb",
        "outputId": "879408c1-698f-48ab-d49d-72e85ca46202"
      },
      "outputs": [],
      "source": [
        "!wget -nc https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qg3wl1ni-13t",
        "outputId": "7a4aac47-7232-4599-de03-c40068d43788"
      },
      "outputs": [],
      "source": [
        "class CharacterTokenizer:\n",
        "    \"\"\"Character level tokenizer that enumerates the first 256 unicode characters\"\"\"\n",
        "    def __init__(self):\n",
        "        self.vocab_size = 256\n",
        "        self.encoding_dict = {chr(token_i): token_i for token_i in range(256)}\n",
        "        self.decoding_dict = {token_i: chr(token_i) for token_i in range(256)}\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f'CharacterTokenizer(vocab_size={self.vocab_size})'\n",
        "\n",
        "    def get_vocab(self) -> dict[str, int]:\n",
        "        return self.encoding_dict\n",
        "\n",
        "    def encode(self, data: str) -> list[int]:\n",
        "        \"\"\"Convert text to tokens\"\"\"\n",
        "        return [self.encoding_dict.get(char, -1) for char in data]\n",
        "\n",
        "    def decode(self, tokens: list[int]) -> str:\n",
        "        \"\"\"Convert tokens to text\"\"\"\n",
        "        return ''.join(self.decoding_dict.get(token, '<unk>') for token in tokens)\n",
        "\n",
        "class CharacterDataset:\n",
        "    def __init__(self, data: str, tokenizer: CharacterTokenizer, context_size: int=256):\n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "        self.vocab_size = len(tokenizer.get_vocab())\n",
        "        self.context_size = context_size\n",
        "\n",
        "    def __repr__(self):\n",
        "        n_chars = len(self.data)\n",
        "        vocab_size = self.vocab_size\n",
        "        context_size = self.context_size\n",
        "        return f'CharacterDataset({n_chars=}, {vocab_size=}, {context_size=})'\n",
        "\n",
        "    @classmethod\n",
        "    def from_textfile(cls, filename: str, context_size: int=256) -> 'CharacterDataset':\n",
        "        \"\"\"Load a textfile and automatically 'train' a character level tokenizer\"\"\"\n",
        "        tokenizer = CharacterTokenizer()\n",
        "        with open(filename, 'r') as fh:\n",
        "            data = fh.read()\n",
        "            return cls(data, tokenizer, context_size=context_size)\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.data) - self.context_size\n",
        "\n",
        "    def __getitem__(self, pos: int) -> torch.tensor:\n",
        "        \"\"\"Return tokens starting at pos up to pos + context_size, targets are shifted by one position\"\"\"\n",
        "        # grab a chunk of block_size characters from the data\n",
        "        chunk = self.data[pos:pos + self.context_size + 1]\n",
        "        # encode every character to an integer\n",
        "        tokens = self.tokenizer.encode(chunk)\n",
        "        # convert to tensor\n",
        "        tokens = torch.tensor(tokens, dtype=torch.long)\n",
        "        # targets are shifted one position from input\n",
        "        return tokens[:-1], tokens[1:]\n",
        "\n",
        "dataset = CharacterDataset.from_textfile('./input.txt')\n",
        "len(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EbXs26mlPa4v"
      },
      "source": [
        "## Model\n",
        "The code below implements a full GPT-style model. All code is in one block to prevent mistakes when changing/updating parts of the implementation. The main functionality is implemented in a few classes (most are similar/identical to the 'naive transformer' we implemented earlier).\n",
        "\n",
        "- `MultiheadDotProductAttention`: Full-blown multihead attention that takes batched input. Evenly chunks channels over heads, so number of channels must be dividable by number of heads.\n",
        "- `PositionwiseMLP`: Position-wise multilayer perceptron to perform communication between channels after multihead attention. This ensures additional communication between heads after attention is calculated (attention only performs linear projection of heads).\n",
        "- `TransformerBlock`: Executes the `DotProductSoftmaxAttention` and `FeedforwardMLP` in order, both with layer normalization to keep our gradients well-behaved, and both with a residual connection to let the original signal flow through (which includes for example positional information).\n",
        "- `AdditivePositionalEmbedding`: A wrapper class to add positional embeddings to previously determined token embeddings.\n",
        "- `GPT`: Combines all of the above functionality and adds dropout and layer normalization in a few places to help with generalization and prevent overfitting. In addition this implements the `generate` method so we can easily sample novel token sequences.\n",
        "\n",
        "### Exercise 1\n",
        "Take a brief (±5min) look at the provided `MultiHeadDotProductAttention` implementation and convince yourself (and/or your neighbor) that the underlying attention mechanisms is the same as we saw in the earlier 'naive' transformer, but that we have added functionality for multiple heads, batched inputs, and random dropout.\n",
        "\n",
        "### Exercise 2\n",
        "Implement the `TransformerBlock` class and the `PositionwiseMLP` so that:\n",
        "- The `PositionwiseMLP`:\n",
        "  - Has identical input and output dimensions\n",
        "  - Used a hidden dimensionality that is 4 times the input dimensionality\n",
        "  - Uses two linear layers with a ReLU activation in between\n",
        "  - Uses dropout on the final layer\n",
        "- The `TransformerBlock`:\n",
        "  - Calculates attention with `MultiHeadDotProductAttention`\n",
        "  - Communicates between channels using the `PositionwiseMLP`\n",
        "  - Includes layer normalization (using [nn.LayerNorm](https://pytorch.org/docs/stable/generated/torch.nn.LayerNorm.html))\n",
        "  - Adds residual connections\n",
        "\n",
        "If you have properly implemented the `PositionwiseMLP` and `TransformerBlock` the codeblock below will be able to generate a token sample from an untrained model when executed.\n",
        "\n",
        "> _Tip:_ start by checking the already filled in `__init__` signatures of the `TransformerBlock`, `MultiHeadDotProductAttention`, and `PositionwiseMLP` classes. This will give you good hints on what parameters should be used where.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214,
          "referenced_widgets": [
            "19c3d5a6d49148b58944c685461dd1fc",
            "75c8e42728e34640a0a838ffb2f7a500",
            "cb72bb1eb55e457596ea6741e03f5ad0",
            "2c9528f0cd3f43b6a3275ecbcc3920fb",
            "56f0099f1c7d47838465506c941f3c49",
            "7a1b6ada774d4610bcaa6b7eeb82830b",
            "c0cf6c38e7624d3e9e741a86071b7f9e",
            "dbd31514fdb34009864709ae3709d174",
            "9e564f01164647149d13ba35a5e4b0ae",
            "efb2a6c5971e46da93edc11838847899",
            "fa7ed7462b814ef5a54dbf91ff74aa78"
          ]
        },
        "id": "y8eU-dgv--dE",
        "outputId": "f43fccbf-19a3-4593-c2e8-ba753f65da78"
      },
      "outputs": [],
      "source": [
        "class MultiheadDotProductAttention(nn.Module):\n",
        "    \"\"\"Multihead dot product softmax attention\"\"\"\n",
        "    def __init__(self, embedding_dim: int, n_heads: int, dropout: float):\n",
        "        super().__init__()\n",
        "        if embedding_dim % n_heads != 0:\n",
        "            raise Exception('n_heads must be dividable by n_embed')\n",
        "\n",
        "        self.n_heads = n_heads\n",
        "\n",
        "        # attention input projections\n",
        "        self.w_q = nn.Linear(in_features=embedding_dim, out_features=embedding_dim)\n",
        "        self.w_k = nn.Linear(in_features=embedding_dim, out_features=embedding_dim)\n",
        "        self.w_v = nn.Linear(in_features=embedding_dim, out_features=embedding_dim)\n",
        "\n",
        "        # output projection\n",
        "        self.out_project = nn.Linear(in_features=embedding_dim, out_features=embedding_dim)\n",
        "\n",
        "        #dropouts\n",
        "        self.attention_dropout = nn.Dropout(dropout)\n",
        "        self.projection_dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x: torch.tensor) -> torch.tensor:\n",
        "        \"\"\"Calculate multihead attention, expects input of shape (batch, context_length, embedding_dim)\"\"\"\n",
        "        batch_dim, context_length, embedding_dim = x.size()\n",
        "\n",
        "        # calculate input projections and divide over heads\n",
        "        # 'view' and 'transpose' reorder in subtly different ways and we need both\n",
        "        # (B, L, n_heads, head_dim) -> (B, n_heads, L, head_dim)\n",
        "        q = self.w_q(x).view(batch_dim, context_length, self.n_heads, embedding_dim // self.n_heads).transpose(1,2)\n",
        "        k = self.w_k(x).view(batch_dim, context_length, self.n_heads, embedding_dim // self.n_heads).transpose(1,2)\n",
        "        v = self.w_v(x).view(batch_dim, context_length, self.n_heads, embedding_dim // self.n_heads).transpose(1,2)\n",
        "\n",
        "        # calculate attention\n",
        "        # (B, n_heads, L, head_size) x (B, n_heads, head_size, L) -> (B, n_heads, L, L)\n",
        "        attention = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(embedding_dim))\n",
        "        # Apply causal attention mask\n",
        "        mask = torch.triu(torch.ones(context_length, context_length, dtype=torch.bool, device=q.device), diagonal=1)\n",
        "        attention = attention.masked_fill(mask, -torch.inf)\n",
        "\n",
        "        # Calculate row-wise logits\n",
        "        attention = F.softmax(attention, dim=-1)\n",
        "\n",
        "        # Random dropout of the attention matrix\n",
        "        attention = self.attention_dropout(attention)\n",
        "\n",
        "        # weight outputs with calculated attention\n",
        "        # (B, n_heads, L, L) x (B, n_heads, L, head_dim) -> (B, n_heads, L, head_dim)\n",
        "        pred = attention @ v\n",
        "\n",
        "        # reshape multiple heads back into contiguous representation\n",
        "        pred = pred.transpose(1, 2).contiguous().view(batch_dim, context_length, embedding_dim)\n",
        "\n",
        "        # return linear projection\n",
        "        return self.projection_dropout(self.out_project(pred))\n",
        "\n",
        "class PositionWiseMLP(nn.Module):\n",
        "    \"\"\"Position-wise feedforward MLP: simple multi-layer perceptron for position-wise exchange of information between channels\"\"\"\n",
        "    def __init__(self, embedding_dim: int, dropout: float):\n",
        "        super().__init__()\n",
        "        self.mlp = # IMPLEMENT ME\n",
        "\n",
        "    def forward(self, x: torch.tensor) -> torch.tensor:\n",
        "        return self.mlp(x)\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "    \"\"\"Transformer block that combines attention and FeedforwardMLP,\n",
        "    both with layer normalization and residual connections\"\"\"\n",
        "    def __init__(self, embedding_dim: int, n_heads:int, dropout:float):\n",
        "        super().__init__()\n",
        "        # IMPLEMENT ME\n",
        "\n",
        "    def forward(self, x: torch.tensor) -> torch.tensor:\n",
        "        \"\"\"Calculate attention and communication between channels, both with residual connections\"\"\"\n",
        "        # IMPLEMENT ME\n",
        "\n",
        "class AdditivePositionalEmbedding(nn.Module):\n",
        "    \"\"\"Wrapper class to add positional encoding to already embedded tokens\"\"\"\n",
        "    def __init__(self, context_size: int, embedding_dim: int):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(num_embeddings=context_size, embedding_dim=embedding_dim)\n",
        "\n",
        "    def forward(self, x: torch.tensor) -> torch.tensor:\n",
        "        \"\"\"Add positional embeddings based on input dimensions, use residual connection\"\"\"\n",
        "        pos = torch.arange(0, x.size(1), dtype=torch.long, device=x.device)\n",
        "        return self.embedding(pos) + x\n",
        "\n",
        "class GPT(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        context_size: int,\n",
        "        tokenizer: CharacterTokenizer,\n",
        "        n_layers: int=6,\n",
        "        n_heads: int=8,\n",
        "        embedding_dim: int=32,\n",
        "        dropout: float=0.1\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.context_size = context_size\n",
        "        self.vocab_size = tokenizer.vocab_size\n",
        "        self.tokenizer = tokenizer\n",
        "        self.n_layers = n_layers\n",
        "        self.n_heads = n_heads\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.dropout = dropout\n",
        "\n",
        "        # transformer architecture (ref. our naive transformer, only difference is in the transformer block)\n",
        "        self.transformer = nn.Sequential(\n",
        "            nn.Embedding(num_embeddings=self.vocab_size, embedding_dim=embedding_dim),\n",
        "            AdditivePositionalEmbedding(context_size, embedding_dim),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Sequential(*[\n",
        "                TransformerBlock(embedding_dim=embedding_dim, n_heads=n_heads, dropout=dropout)\n",
        "                for _ in range(n_layers)\n",
        "            ]),\n",
        "            nn.LayerNorm(embedding_dim),\n",
        "            nn.Linear(in_features=embedding_dim, out_features=self.vocab_size)\n",
        "        )\n",
        "\n",
        "        # weight tying of input embedding and output projection (https://paperswithcode.com/method/weight-tying)\n",
        "        self.transformer[0].weight = self.transformer[-1].weight\n",
        "\n",
        "        # initialize all weights\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        context_size = self.context_size\n",
        "        vocab_size = self.vocab_size\n",
        "        n_attention_layers = self.n_layers\n",
        "        n_heads = self.n_heads\n",
        "        embedding_dim = self.embedding_dim\n",
        "        dropout = self.dropout\n",
        "        num_params = sum(p.numel() for p in self.parameters())\n",
        "        return f'GPT({num_params=}, {context_size=}, {vocab_size=}, {n_attention_layers=}, {n_heads=}, {embedding_dim=}, {dropout=})'\n",
        "\n",
        "    def save(self, filename: str = 'model.pkl') -> None:\n",
        "      \"\"\"Saves all relevant model parameters and weights to a file to reload later\"\"\"\n",
        "      # Identify how the model was initialized\n",
        "      init_params = {k:v for k,v in self.__dict__.items() if k[0] != '_' and k not in ['training','tokenizer','vocab_size']}\n",
        "      # Get model weights\n",
        "      state_dict = {k: v.to('cpu') for k, v in self.state_dict().items()}\n",
        "      # Combine initialization params and weights into a single dict\n",
        "      param_dict = dict(init_params=init_params, state_dict=state_dict)\n",
        "      # save to file\n",
        "      with open(filename,'wb') as fh:\n",
        "        pickle.dump(param_dict, fh)\n",
        "\n",
        "    @classmethod\n",
        "    def load_pretrained(cls, filename: str = 'model.pkl') -> 'GPT':\n",
        "      \"\"\"Loads a pretrained model\"\"\"\n",
        "      # Load params and weights from file\n",
        "      with open(filename,'rb') as fh:\n",
        "        param_dict = pickle.load(fh)\n",
        "      # Initialize model with previous init params\n",
        "      model = cls(**param_dict['init_params'], tokenizer=CharacterTokenizer())\n",
        "      # Apply pretrained model weights\n",
        "      model.load_state_dict({k:v.to(DEVICE) for k,v in param_dict['state_dict'].items()})\n",
        "      return model\n",
        "\n",
        "    def forward(self, tokens: torch.Tensor, targets: torch.Tensor=None) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
        "        logits = self.transformer(tokens)\n",
        "        loss = None if targets is None else F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1), ignore_index=-1)\n",
        "        accuracy = None if targets is None else (logits.argmax(dim=-1) == targets).sum() / targets.numel()\n",
        "        return logits, loss, accuracy\n",
        "\n",
        "    def _init_weights(self, module: nn.Module) -> None:\n",
        "        \"\"\"Empirically this seems to be a good way to initialize\"\"\"\n",
        "        if isinstance(module, nn.Linear):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "            if module.bias is not None:\n",
        "                torch.nn.init.zeros_(module.bias)\n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "\n",
        "    def generate(self, prompt: str = None, sample_length: int=256) -> list[int]:\n",
        "        \"\"\"Generate text from the model, with optional prompt to prime the generation\"\"\"\n",
        "        self.eval()\n",
        "        device = next(self.parameters()).device\n",
        "        if prompt is None:\n",
        "            tokens = torch.zeros(1, dtype=torch.long, device=device)\n",
        "        else:\n",
        "            tokens = torch.tensor(self.tokenizer.encode(prompt), dtype=torch.long, device=device)\n",
        "\n",
        "        for _ in trange(sample_length, desc='Sampling'):\n",
        "            logits,_,_ = self(tokens[-self.context_size:][None])\n",
        "            logits = logits[0,-1,:]\n",
        "\n",
        "            probs = F.softmax(logits, dim=0)\n",
        "\n",
        "            next_token = torch.multinomial(probs, num_samples=1)\n",
        "            tokens = torch.cat([tokens, next_token])\n",
        "        tokens = tokens.tolist() # move from tensor on gpu to list on cpu\n",
        "        return self.tokenizer.decode(tokens)\n",
        "\n",
        "tokenizer = CharacterTokenizer()\n",
        "model = GPT(context_size=dataset.context_size, tokenizer=tokenizer)\n",
        "print(dataset)\n",
        "print(model)\n",
        "sample = model.generate()\n",
        "print(sample)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7IO-_RHBPa4w"
      },
      "source": [
        "## Training\n",
        "We train with the AdamW optimizer for 1000 steps, calculate the loss and accuracy for train and test data, and log every 20 steps.\n",
        "\n",
        "### Exercise 3:\n",
        "Use the codeblock below to train a GPT on the shakespeare dataset using the provided parameterization and generate a few token samples. How does the loss compare to previous implementations in this week? (i.e. markov prediction, 1D CNN, naive transformer). Does the loss converge after 2,000 training steps? What happens to the training efficiency (i.e. what loss do you achieve) if you train using a context length of 8? And what if you use a context length of 256?\n",
        "\n",
        "### Exercise 4:\n",
        "Experiment with different model configurations (i.e. number of layers, number of embedding dimensions, number of heads), what is the best performance you can achieve in 2000 training steps? What happens if you train for longer?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455,
          "referenced_widgets": [
            "98fce8b550bf454d99a41155a2425a5e",
            "abd1121bbf0447ec91c88e99dff7faca",
            "8bd825be680b43df82e42cd8e79ee8d3",
            "0158e5be89bb432d91e8541b64953f4c",
            "7d332a76613e48c8b1c9dd7856195840",
            "63f9dbc8ab134de7a72e416313f7cc9d",
            "699b266d3766494abb11a11e69f58168",
            "c1d2fe698ae64c1bafdeb81ef66ecb05",
            "844463e9a7e4434894ccb42e7d8fd15c",
            "afcdf64eef97412daa4285688294c3fe",
            "bf0a73c91a4f4c429715a606d433925f"
          ]
        },
        "id": "1z_lXej5-_0L",
        "outputId": "78949e96-324c-4247-e2c8-63e2856656c8"
      },
      "outputs": [],
      "source": [
        "train_steps = 1_000\n",
        "batch_size = 32\n",
        "context_size = 512\n",
        "n_layers = 6\n",
        "n_heads = 6\n",
        "embedding_dim = 384\n",
        "learning_rate = 1e-3\n",
        "train_fraction = 0.9\n",
        "dropout = 0.1\n",
        "\n",
        "tokenizer = CharacterTokenizer()\n",
        "\n",
        "dataset = CharacterDataset.from_textfile('./input.txt', context_size=context_size)\n",
        "print(dataset)\n",
        "\n",
        "model = GPT(context_size=context_size, tokenizer=tokenizer, n_layers=n_layers, embedding_dim=embedding_dim, n_heads=n_heads, dropout=dropout)\n",
        "print(model)\n",
        "\n",
        "model.to(DEVICE)\n",
        "model.train()\n",
        "\n",
        "train_dataset, test_dataset = random_split(dataset, [train_fraction, 1 - train_fraction])\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    dataset=train_dataset,\n",
        "    sampler=RandomSampler(train_dataset, num_samples=train_steps * batch_size),\n",
        "    batch_size=batch_size,\n",
        ")\n",
        "test_dataloader = DataLoader(\n",
        "    dataset=test_dataset,\n",
        "    sampler=RandomSampler(test_dataset, replacement=True),\n",
        "    batch_size=batch_size,\n",
        ")\n",
        "test_dataloader = iter(test_dataloader)\n",
        "\n",
        "optimizer = torch.optim.AdamW(params=model.parameters(), lr=learning_rate, betas=(0.9, 0.99))\n",
        "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.01, total_steps=train_steps)\n",
        "model.train()\n",
        "\n",
        "train_losses = []\n",
        "train_accuracies = []\n",
        "test_losses = []\n",
        "test_accuracies = []\n",
        "\n",
        "for i, (train_x, train_y) in enumerate(tqdm(train_dataloader)):\n",
        "    # forward the model\n",
        "    _,train_loss,train_accuracy = model(train_x.to(DEVICE), train_y.to(DEVICE))\n",
        "\n",
        "    # save losses on train and test every 20 iterations\n",
        "    if i % 20 == 0:\n",
        "        train_losses.append(train_loss.item())\n",
        "        train_accuracies.append(train_accuracy.item())\n",
        "        test_x, test_y = next(test_dataloader)\n",
        "        _,test_loss,test_accuracy = model(test_x.to(DEVICE), test_y.to(DEVICE))\n",
        "        test_losses.append(test_loss.item())\n",
        "        test_accuracies.append(test_accuracy.item())\n",
        "\n",
        "    # backprop and update the parameters\n",
        "    model.zero_grad(set_to_none=True)\n",
        "    train_loss.backward()\n",
        "\n",
        "    # Prevent gradients from becoming too large\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "\n",
        "fig,[ax1, ax2] = plt.subplots(ncols=2, figsize=(12,4))\n",
        "ax1.plot(train_losses, label='train loss')\n",
        "ax1.plot(test_losses, label='test loss')\n",
        "ax1.legend()\n",
        "ax2.plot(train_accuracies, label='train accuracy')\n",
        "ax2.plot(test_accuracies, label='test accuracy')\n",
        "ax2.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sf1fQ6k3Pa4x"
      },
      "source": [
        "#### Evaluate\n",
        "We let the trained model generate a piece of text that should somewhat resemble shakespeare. Compare to what was generated from the untrained model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214,
          "referenced_widgets": [
            "dd0aa1be0df24bb5938f71afa9cc20e3",
            "00733eb91e4f48b2a876e72c14e3e9ac",
            "c1a50cdbf341436b93aabee044fa8121",
            "73c425f4198840e0a574cfefd2a0cbb1",
            "f239f29ef7bf4faea02a9083fd5af479",
            "e24faa79d8614843ac25d8ae8de4af3c",
            "6635d39ee45844ff87b5fd5343f83424",
            "8ac957b862f04757bbc082e09aaf545c",
            "f203caa59df34296843aaa8f17f18a18",
            "c3809d988c0849e3912d14444cb974d2",
            "dadde651b63b4fffb1783f578793dbcd"
          ]
        },
        "id": "VczUBBNq_dMn",
        "outputId": "a366ba9e-426a-4f8f-e08b-65b3ba4c5daa"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "sample = model.generate()\n",
        "print(sample)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Bonus: scaling up to increase performance\n",
        "From the previous exercises you have probably noticed that with limited time and compute resources it is difficult to get the GPT model to generate text that resembles english language. To help you get a slightly better idea of the capabilities of our implementation, we have pretrained some models on a variety of datasets. The model implementation is the exact same, so you can load the weights using the `load_pretrained` classmethod. Below we download the files containing the weights and experiment a bit with the pretrained models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!wget -nc https://github.com/holmrenser/deep_learning/raw/refs/heads/main/shakespeare.model.pkl\n",
        "!wget -nc https://github.com/holmrenser/deep_learning/raw/refs/heads/main/war_peace_plain.model.pkl\n",
        "!wget -nc https://github.com/holmrenser/deep_learning/raw/refs/heads/main/openwebtext.model.pkl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Bonus exercise\n",
        "Load each of the three pretrained models (`shakespeare.model.pkl`,`war_peace_plain.model.pkl`, and `openwebtext.model.pkl`) with the code below, note the model size and configuration, and generate a few samples. Make sure to change the prompt (`'prompt me'`) into something else. What do you notice when comparing the models? Can you have a conversation with any of the models?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325,
          "referenced_widgets": [
            "9012fea6900c433e8b900df5251ff873",
            "81f22301a00541979e48cae6cd27be23",
            "29cf4365aec54944b7a65bbf1873529b",
            "938766af1a044dcbb5c86844bdc35b5e",
            "3bba963c0be249b8a0093fea245e0c54",
            "98546b51f466438a8780e61a33482a46",
            "0d8f02ccefef403ca06e20d1e12fc1e8",
            "752174cd88584d6fafb6ac6686e5142d",
            "e3d54f3a893d4487b77c4bb4f1b8fefd",
            "e896e5e77c724935961a7ea2402affd5",
            "07a5279f6d5846b9a20d1475a1f0c3a0"
          ]
        },
        "id": "jjQuAqDLw--h",
        "outputId": "df5b649b-75f4-4f96-fd4c-14fab17a1277"
      },
      "outputs": [],
      "source": [
        "pretrained_model = GPT.load_pretrained('shakespeare.model.pkl')\n",
        "print(pretrained_model)\n",
        "pretrained_model.eval()\n",
        "sample = pretrained_model.generate('prompt me')\n",
        "print(sample)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "deeplearning",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "00733eb91e4f48b2a876e72c14e3e9ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e24faa79d8614843ac25d8ae8de4af3c",
            "placeholder": "​",
            "style": "IPY_MODEL_6635d39ee45844ff87b5fd5343f83424",
            "value": "Sampling: 100%"
          }
        },
        "0158e5be89bb432d91e8541b64953f4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_afcdf64eef97412daa4285688294c3fe",
            "placeholder": "​",
            "style": "IPY_MODEL_bf0a73c91a4f4c429715a606d433925f",
            "value": " 5000/5000 [41:09&lt;00:00,  2.06it/s]"
          }
        },
        "07a5279f6d5846b9a20d1475a1f0c3a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0d8f02ccefef403ca06e20d1e12fc1e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "19c3d5a6d49148b58944c685461dd1fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_75c8e42728e34640a0a838ffb2f7a500",
              "IPY_MODEL_cb72bb1eb55e457596ea6741e03f5ad0",
              "IPY_MODEL_2c9528f0cd3f43b6a3275ecbcc3920fb"
            ],
            "layout": "IPY_MODEL_56f0099f1c7d47838465506c941f3c49"
          }
        },
        "29cf4365aec54944b7a65bbf1873529b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_752174cd88584d6fafb6ac6686e5142d",
            "max": 256,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e3d54f3a893d4487b77c4bb4f1b8fefd",
            "value": 256
          }
        },
        "2c9528f0cd3f43b6a3275ecbcc3920fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_efb2a6c5971e46da93edc11838847899",
            "placeholder": "​",
            "style": "IPY_MODEL_fa7ed7462b814ef5a54dbf91ff74aa78",
            "value": " 256/256 [00:06&lt;00:00,  8.71it/s]"
          }
        },
        "3bba963c0be249b8a0093fea245e0c54": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56f0099f1c7d47838465506c941f3c49": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63f9dbc8ab134de7a72e416313f7cc9d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6635d39ee45844ff87b5fd5343f83424": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "699b266d3766494abb11a11e69f58168": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "73c425f4198840e0a574cfefd2a0cbb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3809d988c0849e3912d14444cb974d2",
            "placeholder": "​",
            "style": "IPY_MODEL_dadde651b63b4fffb1783f578793dbcd",
            "value": " 256/256 [00:01&lt;00:00, 163.73it/s]"
          }
        },
        "752174cd88584d6fafb6ac6686e5142d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75c8e42728e34640a0a838ffb2f7a500": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a1b6ada774d4610bcaa6b7eeb82830b",
            "placeholder": "​",
            "style": "IPY_MODEL_c0cf6c38e7624d3e9e741a86071b7f9e",
            "value": "Sampling: 100%"
          }
        },
        "7a1b6ada774d4610bcaa6b7eeb82830b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d332a76613e48c8b1c9dd7856195840": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81f22301a00541979e48cae6cd27be23": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98546b51f466438a8780e61a33482a46",
            "placeholder": "​",
            "style": "IPY_MODEL_0d8f02ccefef403ca06e20d1e12fc1e8",
            "value": "Sampling: 100%"
          }
        },
        "844463e9a7e4434894ccb42e7d8fd15c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8ac957b862f04757bbc082e09aaf545c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8bd825be680b43df82e42cd8e79ee8d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1d2fe698ae64c1bafdeb81ef66ecb05",
            "max": 5000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_844463e9a7e4434894ccb42e7d8fd15c",
            "value": 5000
          }
        },
        "9012fea6900c433e8b900df5251ff873": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_81f22301a00541979e48cae6cd27be23",
              "IPY_MODEL_29cf4365aec54944b7a65bbf1873529b",
              "IPY_MODEL_938766af1a044dcbb5c86844bdc35b5e"
            ],
            "layout": "IPY_MODEL_3bba963c0be249b8a0093fea245e0c54"
          }
        },
        "938766af1a044dcbb5c86844bdc35b5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e896e5e77c724935961a7ea2402affd5",
            "placeholder": "​",
            "style": "IPY_MODEL_07a5279f6d5846b9a20d1475a1f0c3a0",
            "value": " 256/256 [00:12&lt;00:00, 12.84it/s]"
          }
        },
        "98546b51f466438a8780e61a33482a46": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98fce8b550bf454d99a41155a2425a5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_abd1121bbf0447ec91c88e99dff7faca",
              "IPY_MODEL_8bd825be680b43df82e42cd8e79ee8d3",
              "IPY_MODEL_0158e5be89bb432d91e8541b64953f4c"
            ],
            "layout": "IPY_MODEL_7d332a76613e48c8b1c9dd7856195840"
          }
        },
        "9e564f01164647149d13ba35a5e4b0ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "abd1121bbf0447ec91c88e99dff7faca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63f9dbc8ab134de7a72e416313f7cc9d",
            "placeholder": "​",
            "style": "IPY_MODEL_699b266d3766494abb11a11e69f58168",
            "value": "100%"
          }
        },
        "afcdf64eef97412daa4285688294c3fe": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf0a73c91a4f4c429715a606d433925f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c0cf6c38e7624d3e9e741a86071b7f9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c1a50cdbf341436b93aabee044fa8121": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ac957b862f04757bbc082e09aaf545c",
            "max": 256,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f203caa59df34296843aaa8f17f18a18",
            "value": 256
          }
        },
        "c1d2fe698ae64c1bafdeb81ef66ecb05": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3809d988c0849e3912d14444cb974d2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb72bb1eb55e457596ea6741e03f5ad0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dbd31514fdb34009864709ae3709d174",
            "max": 256,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9e564f01164647149d13ba35a5e4b0ae",
            "value": 256
          }
        },
        "dadde651b63b4fffb1783f578793dbcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dbd31514fdb34009864709ae3709d174": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd0aa1be0df24bb5938f71afa9cc20e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_00733eb91e4f48b2a876e72c14e3e9ac",
              "IPY_MODEL_c1a50cdbf341436b93aabee044fa8121",
              "IPY_MODEL_73c425f4198840e0a574cfefd2a0cbb1"
            ],
            "layout": "IPY_MODEL_f239f29ef7bf4faea02a9083fd5af479"
          }
        },
        "e24faa79d8614843ac25d8ae8de4af3c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3d54f3a893d4487b77c4bb4f1b8fefd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e896e5e77c724935961a7ea2402affd5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efb2a6c5971e46da93edc11838847899": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f203caa59df34296843aaa8f17f18a18": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f239f29ef7bf4faea02a9083fd5af479": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa7ed7462b814ef5a54dbf91ff74aa78": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
