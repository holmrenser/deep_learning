{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a67439a-7953-41aa-b8ac-d010d1c4867a",
   "metadata": {
    "id": "0a67439a-7953-41aa-b8ac-d010d1c4867a"
   },
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9155fe05-e4d6-4387-8e44-c44c38582c6f",
   "metadata": {
    "id": "a2bba09f-05b9-4c33-bba6-0ec7517ce047"
   },
   "source": [
    "## Answers\n",
    "\n",
    "### Exercise 1\n",
    "The only number in the vocabulary is '3', so any other number would work, as would signs like for example a #. These characters get a token -1, '< unk >' (for \"unknown\"). A solution is to use a base vocabulary of all known or relevant single characters.\n",
    "\n",
    "### Exercise 2\n",
    "Code below trains, saves, and loads a BPE tokenizer and prints the learned vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a30da4a-2ae6-4e4e-8f31-d0df4be3b083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and save a BPE tokenizer\n",
    "bpe = BytePairEncoder()\n",
    "bpe.train(data, vocab_size=512)\n",
    "bpe.save(prefix='shakespeare_512')\n",
    "bpe = BytePairEncoder.load(model_filename='./shakespeare_512.model')\n",
    "bpe.get_vocab()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f218f0c-d2c9-4630-ae34-fac44b500c00",
   "metadata": {
    "id": "a2bba09f-05b9-4c33-bba6-0ec7517ce047"
   },
   "source": [
    "There are several words and word fragments, such as 'the', 'and', 'or', 'with', 'have', and 'your'. Interestingly, 'thou' is also in the vocab, indicating the typical language of Shakespeare's texts.\n",
    "\n",
    "### Exercise 3\n",
    "The larger the vocabulary, the more word-like tokens become, up to a point where multiple words get merged into one token (e.g. a vocab_size of 20000 gives 'You shall not ' as one of the tokens). The upper limit is data dependent and occurs when no further merges can happen; for a large dataset this limit will be high."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
